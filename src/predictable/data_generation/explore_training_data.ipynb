{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Training Data\n",
    "\n",
    "This notebook visualizes samples from the training data to understand the input-output relationship."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:56:13.168799Z",
     "start_time": "2025-10-28T12:56:12.804947Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load training data\n",
    "data_dir = Path(\"../data\")\n",
    "train_hidden_states = np.load(data_dir / \"train_hidden_states.npy\")\n",
    "train_remaining_tokens = np.load(data_dir / \"train_remaining_tokens.npy\")\n",
    "train_token_metadata = np.load(data_dir / \"train_token_metadata.npy\")\n",
    "\n",
    "print(f\"Training data shape:\")\n",
    "print(f\"Hidden states: {train_hidden_states.shape}\")\n",
    "print(f\"Remaining tokens: {train_remaining_tokens.shape}\")\n",
    "print(f\"Token metadata: {train_token_metadata.shape}\")\n",
    "print(f\"\\nTotal samples: {len(train_hidden_states):,}\")\n",
    "print(f\"\\nMetadata fields: {train_token_metadata.dtype.names}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:\n",
      "Hidden states: (44544, 3072)\n",
      "Remaining tokens: (44544,)\n",
      "Token metadata: (44544,)\n",
      "\n",
      "Total samples: 44,544\n",
      "\n",
      "Metadata fields: ('token_id', 'token_text')\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Points\n",
    "\n",
    "Let's look at a few random samples to see the input-output pairs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T12:57:36.119198Z",
     "start_time": "2025-10-28T12:57:36.113397Z"
    }
   },
   "source": [
    "# Show 10 random samples\n",
    "np.random.seed(42)\n",
    "sample_indices = range(10, 20)\n",
    "\n",
    "print(\"Random samples from training data:\")\n",
    "print(\"=\"*60)\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    hidden_state = train_hidden_states[idx]\n",
    "    remaining = train_remaining_tokens[idx]\n",
    "    token_id = train_token_metadata[idx]['token_id']\n",
    "    token_text = train_token_metadata[idx]['token_text']\n",
    "    \n",
    "    print(f\"\\nSample {i+1} (index {idx}):\")\n",
    "    print(f\"  Token: '{token_text}' (id={token_id})\")\n",
    "    print(f\"  Input (hidden state): shape={hidden_state.shape}, norm={np.linalg.norm(hidden_state):.4f}\")\n",
    "    print(f\"  First 10 values: {hidden_state[:10]}\")\n",
    "    print(f\"  Output (remaining tokens): {remaining}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random samples from training data:\n",
      "============================================================\n",
      "\n",
      "Sample 1 (index 10):\n",
      "  Token: '<|eot_id|>' (id=128009)\n",
      "  Input (hidden state): shape=(3072,), norm=82.8750\n",
      "  First 10 values: [-0.02248  2.984    1.709   -1.4375   0.4695  -0.581   -0.2146   3.01\n",
      "  1.303   -1.59   ]\n",
      "  Output (remaining tokens): 0\n",
      "\n",
      "Sample 2 (index 11):\n",
      "  Token: '\n",
      "\n",
      "' (id=271)\n",
      "  Input (hidden state): shape=(3072,), norm=89.6250\n",
      "  First 10 values: [-0.9077  1.297   0.411  -0.6777  1.9375 -0.3428 -1.988   1.863  -1.017\n",
      " -1.581 ]\n",
      "  Output (remaining tokens): 10\n",
      "\n",
      "Sample 3 (index 12):\n",
      "  Token: 'world' (id=14957)\n",
      "  Input (hidden state): shape=(3072,), norm=88.8750\n",
      "  First 10 values: [ 2.158   1.868  -1.372   0.8516 -0.6445 -0.9883 -2.36    0.1552  0.3953\n",
      " -2.592 ]\n",
      "  Output (remaining tokens): 9\n",
      "\n",
      "Sample 4 (index 13):\n",
      "  Token: '\n",
      "' (id=198)\n",
      "  Input (hidden state): shape=(3072,), norm=88.4375\n",
      "  First 10 values: [ 0.3237   0.798   -0.06714 -0.592    0.5146  -1.365   -3.164    0.994\n",
      "  1.65    -1.624  ]\n",
      "  Output (remaining tokens): 8\n",
      "\n",
      "Sample 5 (index 14):\n",
      "  Token: 'world' (id=14957)\n",
      "  Input (hidden state): shape=(3072,), norm=87.8125\n",
      "  First 10 values: [-0.02754  0.793   -0.0866  -0.01018 -0.2732  -1.41    -0.676    1.245\n",
      "  1.157   -1.692  ]\n",
      "  Output (remaining tokens): 7\n",
      "\n",
      "Sample 6 (index 15):\n",
      "  Token: '\n",
      "' (id=198)\n",
      "  Input (hidden state): shape=(3072,), norm=83.3750\n",
      "  First 10 values: [ 0.7427  1.133   2.01    0.0737  0.6123 -1.37   -2.994   1.652   1.315\n",
      " -1.595 ]\n",
      "  Output (remaining tokens): 6\n",
      "\n",
      "Sample 7 (index 16):\n",
      "  Token: 'world' (id=14957)\n",
      "  Input (hidden state): shape=(3072,), norm=88.7500\n",
      "  First 10 values: [-0.6763 -0.4727 -2.227  -0.1085 -0.674  -1.931  -1.449   1.921   0.8945\n",
      " -1.59  ]\n",
      "  Output (remaining tokens): 5\n",
      "\n",
      "Sample 8 (index 17):\n",
      "  Token: '\n",
      "' (id=198)\n",
      "  Input (hidden state): shape=(3072,), norm=85.3750\n",
      "  First 10 values: [ 0.6587  1.711   1.723   0.984   0.1381 -0.9404 -2.98    1.675   1.237\n",
      " -2.064 ]\n",
      "  Output (remaining tokens): 4\n",
      "\n",
      "Sample 9 (index 18):\n",
      "  Token: 'world' (id=14957)\n",
      "  Input (hidden state): shape=(3072,), norm=88.3750\n",
      "  First 10 values: [-0.2241 -0.2722 -1.706  -0.2087 -0.1266 -1.568  -1.317   1.818   0.9453\n",
      " -2.09  ]\n",
      "  Output (remaining tokens): 3\n",
      "\n",
      "Sample 10 (index 19):\n",
      "  Token: '\n",
      "' (id=198)\n",
      "  Input (hidden state): shape=(3072,), norm=82.6875\n",
      "  First 10 values: [ 0.317   2.518   1.449   0.757   0.2323 -0.9155 -1.894   1.957   1.07\n",
      " -1.218 ]\n",
      "  Output (remaining tokens): 2\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Remaining Tokens\n",
    "\n",
    "Let's visualize the distribution of the target variable (remaining tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_remaining_tokens, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Remaining Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Remaining Tokens')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Statistics\n",
    "plt.subplot(1, 2, 2)\n",
    "stats_text = f\"\"\"Statistics:\n",
    "Min: {train_remaining_tokens.min()}\n",
    "Max: {train_remaining_tokens.max()}\n",
    "Mean: {train_remaining_tokens.mean():.2f}\n",
    "Median: {np.median(train_remaining_tokens):.2f}\n",
    "Std: {train_remaining_tokens.std():.2f}\n",
    "\n",
    "Unique values: {len(np.unique(train_remaining_tokens))}\n",
    "\"\"\"\n",
    "plt.text(0.1, 0.5, stats_text, fontsize=12, family='monospace',\n",
    "         verticalalignment='center')\n",
    "plt.axis('off')\n",
    "plt.title('Target Variable Statistics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden State Analysis\n",
    "\n",
    "Let's examine the hidden state vectors to understand their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics across all hidden states\n",
    "hidden_norms = np.linalg.norm(train_hidden_states, axis=1)\n",
    "hidden_means = train_hidden_states.mean(axis=1)\n",
    "hidden_stds = train_hidden_states.std(axis=1)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Norms\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(hidden_norms, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('L2 Norm')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Hidden State Norms')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Means\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(hidden_means, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Mean Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Hidden State Means')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Stds\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(hidden_stds, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Standard Deviation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Hidden State Std Devs')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship: Hidden States vs Remaining Tokens\n",
    "\n",
    "Let's explore if there's any obvious relationship between hidden state properties and remaining tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Norm vs Remaining Tokens\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(train_remaining_tokens, hidden_norms, alpha=0.1, s=1)\n",
    "plt.xlabel('Remaining Tokens')\n",
    "plt.ylabel('Hidden State Norm')\n",
    "plt.title('Norm vs Remaining Tokens')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Mean vs Remaining Tokens\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(train_remaining_tokens, hidden_means, alpha=0.1, s=1)\n",
    "plt.xlabel('Remaining Tokens')\n",
    "plt.ylabel('Hidden State Mean')\n",
    "plt.title('Mean vs Remaining Tokens')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Std vs Remaining Tokens\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(train_remaining_tokens, hidden_stds, alpha=0.1, s=1)\n",
    "plt.xlabel('Remaining Tokens')\n",
    "plt.ylabel('Hidden State Std Dev')\n",
    "plt.title('Std Dev vs Remaining Tokens')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Sequence Analysis\n",
    "\n",
    "Let's look at how remaining tokens decrease during generation for specific examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find samples that form sequences (consecutive remaining token counts)\n# This assumes the data was generated sequentially before shuffling\n\nprint(\"Examples of how remaining tokens change during generation:\")\nprint(\"=\"*60)\n\n# Show first 20 samples with their tokens\nprint(\"\\nFirst 20 samples (may show part of a generation sequence):\")\nfor i in range(min(20, len(train_remaining_tokens))):\n    token_text = train_token_metadata[i]['token_text']\n    token_id = train_token_metadata[i]['token_id']\n    print(f\"Sample {i:3d}: token='{token_text:20s}' (id={token_id:6d}), remaining={train_remaining_tokens[i]:3d}\")\n\n# Find sequences where remaining tokens decrease by 1\nprint(\"\\n\\nLooking for consecutive decreasing sequences...\")\nsequence_starts = []\nfor i in range(len(train_remaining_tokens) - 5):\n    # Check if we have a decreasing sequence\n    is_sequence = all(\n        train_remaining_tokens[i+j] - train_remaining_tokens[i+j+1] == 1\n        for j in range(4)\n    )\n    if is_sequence:\n        sequence_starts.append(i)\n        if len(sequence_starts) >= 3:  # Show first 3 found\n            break\n\nif sequence_starts:\n    for seq_start in sequence_starts:\n        print(f\"\\nSequence starting at index {seq_start}:\")\n        for j in range(10):\n            if seq_start + j < len(train_remaining_tokens):\n                token_text = train_token_metadata[seq_start + j]['token_text']\n                print(f\"  Step {j}: token='{token_text:20s}' remaining={train_remaining_tokens[seq_start + j]}\")\nelse:\n    print(\"No obvious sequences found (data is shuffled)\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

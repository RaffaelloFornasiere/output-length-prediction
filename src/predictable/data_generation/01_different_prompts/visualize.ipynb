{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Dataset 01: Different Prompts Visualization\n\nThis notebook visualizes the dataset generated using multiple different prompt templates to understand the input-output relationship."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:39:46.589570Z",
     "start_time": "2025-11-10T21:39:46.524739Z"
    }
   },
   "source": "import numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\n# Load training data\ndata_dir = Path(\"data\")\ntrain_hidden_states = np.load(data_dir / \"train_hidden_states.npy\")\ntrain_remaining_tokens = np.load(data_dir / \"train_remaining_tokens.npy\")\ntrain_token_metadata = np.load(data_dir / \"train_token_metadata.npy\")\n\nprint(f\"Training data shape:\")\nprint(f\"Hidden states: {train_hidden_states.shape}\")\nprint(f\"Remaining tokens: {train_remaining_tokens.shape}\")\nprint(f\"Token metadata: {train_token_metadata.shape}\")\nprint(f\"\\nTotal samples: {len(train_hidden_states):,}\")\nprint(f\"\\nMetadata fields: {train_token_metadata.dtype.names}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:\n",
      "Hidden states: (37817, 3072)\n",
      "Remaining tokens: (37817,)\n",
      "Token metadata: (37817,)\n",
      "\n",
      "Total samples: 37,817\n",
      "\n",
      "Metadata fields: ('token_id', 'token_text')\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Points\n",
    "\n",
    "Let's look at a few random samples to see the input-output pairs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:48:57.638942Z",
     "start_time": "2025-11-10T21:48:57.626730Z"
    }
   },
   "source": [
    "# Show 10 random samples\n",
    "np.random.seed(42)\n",
    "sample_indices = range(10, 20)\n",
    "\n",
    "print(\"Random samples from training data:\")\n",
    "print(\"=\"*60)\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    hidden_state = train_hidden_states[idx]\n",
    "    remaining = train_remaining_tokens[idx]\n",
    "    token_id = train_token_metadata[idx]['token_id']\n",
    "    token_text = train_token_metadata[idx]['token_text']\n",
    "    \n",
    "    print(f\"\\nSample {i+1} (index {idx}):\")\n",
    "    print(f\"  Token: '{token_text}' (id={token_id})\")\n",
    "    print(f\"  Input (hidden state): shape={hidden_state.shape}, norm={np.linalg.norm(hidden_state):.4f}\")\n",
    "    print(f\"  First 10 values: {hidden_state[:10]}\")\n",
    "    print(f\"  Output (remaining tokens): {remaining}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random samples from training data:\n",
      "============================================================\n",
      "\n",
      "Sample 1 (index 10):\n",
      "  Token: '1' (id=16)\n",
      "  Input (hidden state): shape=(3072,), norm=89.1250\n",
      "  First 10 values: [ 0.04495 -1.132    0.2103  -0.686   -0.324   -2.238   -0.10504  3.17\n",
      " -0.3372  -2.094  ]\n",
      "  Output (remaining tokens): 59\n",
      "\n",
      "Sample 2 (index 11):\n",
      "  Token: '.' (id=13)\n",
      "  Input (hidden state): shape=(3072,), norm=88.1875\n",
      "  First 10 values: [-0.1519 -0.9116  5.203  -2.49   -0.989  -0.8203 -0.2336  0.318  -0.2212\n",
      " -1.076 ]\n",
      "  Output (remaining tokens): 58\n",
      "\n",
      "Sample 3 (index 12):\n",
      "  Token: ' The' (id=578)\n",
      "  Input (hidden state): shape=(3072,), norm=84.6875\n",
      "  First 10 values: [-1.110e-03 -8.047e-01  9.131e-01 -8.008e-01  2.196e-01 -2.801e+00\n",
      "  2.939e-01  1.860e+00  1.357e-01 -1.169e+00]\n",
      "  Output (remaining tokens): 57\n",
      "\n",
      "Sample 4 (index 13):\n",
      "  Token: ' world' (id=1917)\n",
      "  Input (hidden state): shape=(3072,), norm=86.7500\n",
      "  First 10 values: [-1.192   -0.4163   3.018   -1.173    0.2212   0.03424 -0.3984   1.78\n",
      "  0.19    -0.9526 ]\n",
      "  Output (remaining tokens): 56\n",
      "\n",
      "Sample 5 (index 14):\n",
      "  Token: ' is' (id=374)\n",
      "  Input (hidden state): shape=(3072,), norm=89.4375\n",
      "  First 10 values: [ 1.52    1.15    1.604  -0.598   0.261  -1.778   0.9053  2.293   3.31\n",
      " -1.682 ]\n",
      "  Output (remaining tokens): 55\n",
      "\n",
      "Sample 6 (index 15):\n",
      "  Token: ' a' (id=264)\n",
      "  Input (hidden state): shape=(3072,), norm=89.5625\n",
      "  First 10 values: [ 0.3655  -0.0425  -0.4243   1.805   -0.2092  -2.57     0.04205  3.16\n",
      "  3.174   -0.05713]\n",
      "  Output (remaining tokens): 54\n",
      "\n",
      "Sample 7 (index 16):\n",
      "  Token: ' complex' (id=6485)\n",
      "  Input (hidden state): shape=(3072,), norm=90.0625\n",
      "  First 10 values: [-0.2094  -1.318   -0.629   -1.388   -0.07715 -3.693    0.509    2.691\n",
      "  3.19    -0.1578 ]\n",
      "  Output (remaining tokens): 53\n",
      "\n",
      "Sample 8 (index 17):\n",
      "  Token: ' and' (id=323)\n",
      "  Input (hidden state): shape=(3072,), norm=89.1250\n",
      "  First 10 values: [-0.03072 -0.758    0.4487  -0.8237   0.687   -4.902    2.047    0.9126\n",
      "  1.094   -0.1398 ]\n",
      "  Output (remaining tokens): 52\n",
      "\n",
      "Sample 9 (index 18):\n",
      "  Token: ' dynamic' (id=8915)\n",
      "  Input (hidden state): shape=(3072,), norm=89.9375\n",
      "  First 10 values: [ 0.3806  0.4421 -0.2299 -1.686   0.4084 -3.338   1.556   2.342   2.588\n",
      " -1.426 ]\n",
      "  Output (remaining tokens): 51\n",
      "\n",
      "Sample 10 (index 19):\n",
      "  Token: ' place' (id=2035)\n",
      "  Input (hidden state): shape=(3072,), norm=88.8125\n",
      "  First 10 values: [ 0.288  -0.1562  1.388  -1.673   1.357  -3.295   2.133   0.7236  0.264\n",
      " -0.5967]\n",
      "  Output (remaining tokens): 50\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Sequence Analysis\n",
    "\n",
    "Let's look at how remaining tokens decrease during generation for specific examples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:47:32.783792Z",
     "start_time": "2025-11-10T21:47:32.761186Z"
    }
   },
   "source": "# Find samples that form sequences (consecutive remaining token counts)\n# This assumes the data was generated sequentially before shuffling\n\nprint(\"Examples of how remaining tokens change during generation:\")\nprint(\"=\"*60)\n\n# Show first 20 samples with their tokens\nprint(\"\\nFirst 20 samples (may show part of a generation sequence):\")\nfor i in range(min(20, len(train_remaining_tokens))):\n    token_text = train_token_metadata[i]['token_text']\n    token_id = train_token_metadata[i]['token_id']\n    print(f\"Sample {i:3d}: token={repr(token_text):22s} (id={token_id:6d}), remaining={train_remaining_tokens[i]:3d}\")\n\n# Find sequences where remaining tokens decrease by 1\nprint(\"\\n\\nLooking for consecutive decreasing sequences...\")\nsequence_starts = []\nfor i in range(len(train_remaining_tokens) - 5):\n    # Check if we have a decreasing sequence\n    is_sequence = all(\n        train_remaining_tokens[i+j] - train_remaining_tokens[i+j+1] == 1\n        for j in range(4)\n    )\n    if is_sequence:\n        sequence_starts.append(i)\n        if len(sequence_starts) >= 3:  # Show first 3 found\n            break\n\nif sequence_starts:\n    for seq_start in sequence_starts:\n        print(f\"\\nSequence starting at index {seq_start}:\")\n        for j in range(10):\n            if seq_start + j < len(train_remaining_tokens):\n                token_text = train_token_metadata[seq_start + j]['token_text']\n                print(f\"  Step {j}: token={repr(token_text):22s} remaining={train_remaining_tokens[seq_start + j]}\")\nelse:\n    print(\"No obvious sequences found (data is shuffled)\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of how remaining tokens change during generation:\n",
      "============================================================\n",
      "\n",
      "First 20 samples (may show part of a generation sequence):\n",
      "Sample   0: token=np.str_('hello')       (id= 15339), remaining=  9\n",
      "Sample   1: token=np.str_('\\n')          (id=   198), remaining=  8\n",
      "Sample   2: token=np.str_('hello')       (id= 15339), remaining=  7\n",
      "Sample   3: token=np.str_('\\n')          (id=   198), remaining=  6\n",
      "Sample   4: token=np.str_('hello')       (id= 15339), remaining=  5\n",
      "Sample   5: token=np.str_('\\n')          (id=   198), remaining=  4\n",
      "Sample   6: token=np.str_('hello')       (id= 15339), remaining=  3\n",
      "Sample   7: token=np.str_('\\n')          (id=   198), remaining=  2\n",
      "Sample   8: token=np.str_('hello')       (id= 15339), remaining=  1\n",
      "Sample   9: token=np.str_('<|eot_id|>')  (id=128009), remaining=  0\n",
      "Sample  10: token=np.str_('1')           (id=    16), remaining= 59\n",
      "Sample  11: token=np.str_('.')           (id=    13), remaining= 58\n",
      "Sample  12: token=np.str_(' The')        (id=   578), remaining= 57\n",
      "Sample  13: token=np.str_(' world')      (id=  1917), remaining= 56\n",
      "Sample  14: token=np.str_(' is')         (id=   374), remaining= 55\n",
      "Sample  15: token=np.str_(' a')          (id=   264), remaining= 54\n",
      "Sample  16: token=np.str_(' complex')    (id=  6485), remaining= 53\n",
      "Sample  17: token=np.str_(' and')        (id=   323), remaining= 52\n",
      "Sample  18: token=np.str_(' dynamic')    (id=  8915), remaining= 51\n",
      "Sample  19: token=np.str_(' place')      (id=  2035), remaining= 50\n",
      "\n",
      "\n",
      "Looking for consecutive decreasing sequences...\n",
      "\n",
      "Sequence starting at index 0:\n",
      "  Step 0: token=np.str_('hello')       remaining=9\n",
      "  Step 1: token=np.str_('\\n')          remaining=8\n",
      "  Step 2: token=np.str_('hello')       remaining=7\n",
      "  Step 3: token=np.str_('\\n')          remaining=6\n",
      "  Step 4: token=np.str_('hello')       remaining=5\n",
      "  Step 5: token=np.str_('\\n')          remaining=4\n",
      "  Step 6: token=np.str_('hello')       remaining=3\n",
      "  Step 7: token=np.str_('\\n')          remaining=2\n",
      "  Step 8: token=np.str_('hello')       remaining=1\n",
      "  Step 9: token=np.str_('<|eot_id|>')  remaining=0\n",
      "\n",
      "Sequence starting at index 1:\n",
      "  Step 0: token=np.str_('\\n')          remaining=8\n",
      "  Step 1: token=np.str_('hello')       remaining=7\n",
      "  Step 2: token=np.str_('\\n')          remaining=6\n",
      "  Step 3: token=np.str_('hello')       remaining=5\n",
      "  Step 4: token=np.str_('\\n')          remaining=4\n",
      "  Step 5: token=np.str_('hello')       remaining=3\n",
      "  Step 6: token=np.str_('\\n')          remaining=2\n",
      "  Step 7: token=np.str_('hello')       remaining=1\n",
      "  Step 8: token=np.str_('<|eot_id|>')  remaining=0\n",
      "  Step 9: token=np.str_('1')           remaining=59\n",
      "\n",
      "Sequence starting at index 2:\n",
      "  Step 0: token=np.str_('hello')       remaining=7\n",
      "  Step 1: token=np.str_('\\n')          remaining=6\n",
      "  Step 2: token=np.str_('hello')       remaining=5\n",
      "  Step 3: token=np.str_('\\n')          remaining=4\n",
      "  Step 4: token=np.str_('hello')       remaining=3\n",
      "  Step 5: token=np.str_('\\n')          remaining=2\n",
      "  Step 6: token=np.str_('hello')       remaining=1\n",
      "  Step 7: token=np.str_('<|eot_id|>')  remaining=0\n",
      "  Step 8: token=np.str_('1')           remaining=59\n",
      "  Step 9: token=np.str_('.')           remaining=58\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": "## Complete Output Reconstruction\n\nSince the data is stored in generation order (not shuffled), we can reconstruct complete outputs by grouping tokens until we reach remaining_tokens == 0.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Reconstruct complete outputs\ndef reconstruct_sequences(remaining_tokens, token_metadata, max_sequences=10):\n    \"\"\"Group tokens into complete generation sequences.\"\"\"\n    sequences = []\n    current_sequence = []\n\n    for i in range(len(remaining_tokens)):\n        token_text = str(token_metadata[i]['token_text'])\n        remaining = remaining_tokens[i]\n\n        current_sequence.append({\n            'token': token_text,\n            'remaining': remaining,\n            'index': i\n        })\n\n        # End of sequence\n        if remaining == 0:\n            sequences.append(current_sequence)\n            current_sequence = []\n\n            if len(sequences) >= max_sequences:\n                break\n\n    return sequences\n\n# Reconstruct first 10 complete sequences\nsequences = reconstruct_sequences(train_remaining_tokens, train_token_metadata, max_sequences=10)\n\nprint(f\"Reconstructed {len(sequences)} complete generation sequences\")\nprint(\"=\"*80)\n\nfor i, seq in enumerate(sequences):\n    # Reconstruct the full output text\n    output_text = ''.join([token['token'] for token in seq])\n    num_tokens = len(seq)\n    start_idx = seq[0]['index']\n    end_idx = seq[-1]['index']\n\n    print(f\"\\nSequence {i+1}:\")\n    print(f\"  Indices: {start_idx} to {end_idx}\")\n    print(f\"  Total tokens: {num_tokens}\")\n    print(f\"  Output: {repr(output_text)}\")\n    print(f\"  Token breakdown:\")\n    for j, token_info in enumerate(seq[:15]):  # Show first 15 tokens\n        print(f\"    {j+1:2d}. {repr(token_info['token']):20s} (remaining: {token_info['remaining']:2d})\")\n    if len(seq) > 15:\n        print(f\"    ... ({len(seq) - 15} more tokens)\")\n    print()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:56:19.151537Z",
     "start_time": "2025-11-10T21:56:19.140138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed 10 complete generation sequences\n",
      "================================================================================\n",
      "\n",
      "Sequence 1:\n",
      "  Indices: 0 to 9\n",
      "  Total tokens: 10\n",
      "  Output: 'hello\\nhello\\nhello\\nhello\\nhello<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'hello'              (remaining:  9)\n",
      "     2. '\\n'                 (remaining:  8)\n",
      "     3. 'hello'              (remaining:  7)\n",
      "     4. '\\n'                 (remaining:  6)\n",
      "     5. 'hello'              (remaining:  5)\n",
      "     6. '\\n'                 (remaining:  4)\n",
      "     7. 'hello'              (remaining:  3)\n",
      "     8. '\\n'                 (remaining:  2)\n",
      "     9. 'hello'              (remaining:  1)\n",
      "    10. '<|eot_id|>'         (remaining:  0)\n",
      "\n",
      "\n",
      "Sequence 2:\n",
      "  Indices: 10 to 69\n",
      "  Total tokens: 60\n",
      "  Output: '1. The world is a complex and dynamic place.\\n2. The world is full of diverse cultures and landscapes.\\n3. The world is a place of endless possibilities.\\n4. The world is a stage for human drama and comedy.\\n5. The world is a place of wonder and discovery.<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. '1'                  (remaining: 59)\n",
      "     2. '.'                  (remaining: 58)\n",
      "     3. ' The'               (remaining: 57)\n",
      "     4. ' world'             (remaining: 56)\n",
      "     5. ' is'                (remaining: 55)\n",
      "     6. ' a'                 (remaining: 54)\n",
      "     7. ' complex'           (remaining: 53)\n",
      "     8. ' and'               (remaining: 52)\n",
      "     9. ' dynamic'           (remaining: 51)\n",
      "    10. ' place'             (remaining: 50)\n",
      "    11. '.\\n'                (remaining: 49)\n",
      "    12. '2'                  (remaining: 48)\n",
      "    13. '.'                  (remaining: 47)\n",
      "    14. ' The'               (remaining: 46)\n",
      "    15. ' world'             (remaining: 45)\n",
      "    ... (45 more tokens)\n",
      "\n",
      "\n",
      "Sequence 3:\n",
      "  Indices: 70 to 75\n",
      "  Total tokens: 6\n",
      "  Output: 'catcatcatcatcat<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'cat'                (remaining:  5)\n",
      "     2. 'cat'                (remaining:  4)\n",
      "     3. 'cat'                (remaining:  3)\n",
      "     4. 'cat'                (remaining:  2)\n",
      "     5. 'cat'                (remaining:  1)\n",
      "     6. '<|eot_id|>'         (remaining:  0)\n",
      "\n",
      "\n",
      "Sequence 4:\n",
      "  Indices: 76 to 81\n",
      "  Total tokens: 6\n",
      "  Output: 'dog dog dog dog dog<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'dog'                (remaining:  5)\n",
      "     2. ' dog'               (remaining:  4)\n",
      "     3. ' dog'               (remaining:  3)\n",
      "     4. ' dog'               (remaining:  2)\n",
      "     5. ' dog'               (remaining:  1)\n",
      "     6. '<|eot_id|>'         (remaining:  0)\n",
      "\n",
      "\n",
      "Sequence 5:\n",
      "  Indices: 82 to 91\n",
      "  Total tokens: 10\n",
      "  Output: 'python\\npython\\npython\\npython\\npython<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'python'             (remaining:  9)\n",
      "     2. '\\n'                 (remaining:  8)\n",
      "     3. 'python'             (remaining:  7)\n",
      "     4. '\\n'                 (remaining:  6)\n",
      "     5. 'python'             (remaining:  5)\n",
      "     6. '\\n'                 (remaining:  4)\n",
      "     7. 'python'             (remaining:  3)\n",
      "     8. '\\n'                 (remaining:  2)\n",
      "     9. 'python'             (remaining:  1)\n",
      "    10. '<|eot_id|>'         (remaining:  0)\n",
      "\n",
      "\n",
      "Sequence 6:\n",
      "  Indices: 92 to 133\n",
      "  Total tokens: 42\n",
      "  Output: 'Here are 5 test entries:\\n\\n1. Test entry 1\\n2. Test entry 2\\n3. Test entry 3\\n4. Test entry 4\\n5. Test entry 5<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'Here'               (remaining: 41)\n",
      "     2. ' are'               (remaining: 40)\n",
      "     3. ' '                  (remaining: 39)\n",
      "     4. '5'                  (remaining: 38)\n",
      "     5. ' test'              (remaining: 37)\n",
      "     6. ' entries'           (remaining: 36)\n",
      "     7. ':\\n\\n'              (remaining: 35)\n",
      "     8. '1'                  (remaining: 34)\n",
      "     9. '.'                  (remaining: 33)\n",
      "    10. ' Test'              (remaining: 32)\n",
      "    11. ' entry'             (remaining: 31)\n",
      "    12. ' '                  (remaining: 30)\n",
      "    13. '1'                  (remaining: 29)\n",
      "    14. '\\n'                 (remaining: 28)\n",
      "    15. '2'                  (remaining: 27)\n",
      "    ... (27 more tokens)\n",
      "\n",
      "\n",
      "Sequence 7:\n",
      "  Indices: 134 to 143\n",
      "  Total tokens: 10\n",
      "  Output: 'apple * apple * apple * apple * apple<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'apple'              (remaining:  9)\n",
      "     2. ' *'                 (remaining:  8)\n",
      "     3. ' apple'             (remaining:  7)\n",
      "     4. ' *'                 (remaining:  6)\n",
      "     5. ' apple'             (remaining:  5)\n",
      "     6. ' *'                 (remaining:  4)\n",
      "     7. ' apple'             (remaining:  3)\n",
      "     8. ' *'                 (remaining:  2)\n",
      "     9. ' apple'             (remaining:  1)\n",
      "    10. '<|eot_id|>'         (remaining:  0)\n",
      "\n",
      "\n",
      "Sequence 8:\n",
      "  Indices: 144 to 199\n",
      "  Total tokens: 56\n",
      "  Output: 'Here is a Python function that accomplishes this:\\n\\n```python\\ndef repeat_blue():\\n    return \"blue\" * 5\\n\\nprint(repeat_blue())\\n```\\n\\nThis function uses Python\\'s string multiplication operator (`*`) to repeat the string \"blue\" 5 times.<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'Here'               (remaining: 55)\n",
      "     2. ' is'                (remaining: 54)\n",
      "     3. ' a'                 (remaining: 53)\n",
      "     4. ' Python'            (remaining: 52)\n",
      "     5. ' function'          (remaining: 51)\n",
      "     6. ' that'              (remaining: 50)\n",
      "     7. ' accompl'           (remaining: 49)\n",
      "     8. 'ishes'              (remaining: 48)\n",
      "     9. ' this'              (remaining: 47)\n",
      "    10. ':\\n\\n'              (remaining: 46)\n",
      "    11. '```'                (remaining: 45)\n",
      "    12. 'python'             (remaining: 44)\n",
      "    13. '\\n'                 (remaining: 43)\n",
      "    14. 'def'                (remaining: 42)\n",
      "    15. ' repeat'            (remaining: 41)\n",
      "    ... (41 more tokens)\n",
      "\n",
      "\n",
      "Sequence 9:\n",
      "  Indices: 200 to 222\n",
      "  Total tokens: 23\n",
      "  Output: 'I\\'ll make sure to limit the repetition of the word \"sun\" to 5 times in my responses.<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'I'                  (remaining: 22)\n",
      "     2. \"'ll\"                (remaining: 21)\n",
      "     3. ' make'              (remaining: 20)\n",
      "     4. ' sure'              (remaining: 19)\n",
      "     5. ' to'                (remaining: 18)\n",
      "     6. ' limit'             (remaining: 17)\n",
      "     7. ' the'               (remaining: 16)\n",
      "     8. ' repetition'        (remaining: 15)\n",
      "     9. ' of'                (remaining: 14)\n",
      "    10. ' the'               (remaining: 13)\n",
      "    11. ' word'              (remaining: 12)\n",
      "    12. ' \"'                 (remaining: 11)\n",
      "    13. 'sun'                (remaining: 10)\n",
      "    14. '\"'                  (remaining:  9)\n",
      "    15. ' to'                (remaining:  8)\n",
      "    ... (8 more tokens)\n",
      "\n",
      "\n",
      "Sequence 10:\n",
      "  Indices: 223 to 232\n",
      "  Total tokens: 10\n",
      "  Output: 'code\\ncode\\ncode\\ncode\\ncode<|eot_id|>'\n",
      "  Token breakdown:\n",
      "     1. 'code'               (remaining:  9)\n",
      "     2. '\\n'                 (remaining:  8)\n",
      "     3. 'code'               (remaining:  7)\n",
      "     4. '\\n'                 (remaining:  6)\n",
      "     5. 'code'               (remaining:  5)\n",
      "     6. '\\n'                 (remaining:  4)\n",
      "     7. 'code'               (remaining:  3)\n",
      "     8. '\\n'                 (remaining:  2)\n",
      "     9. 'code'               (remaining:  1)\n",
      "    10. '<|eot_id|>'         (remaining:  0)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
